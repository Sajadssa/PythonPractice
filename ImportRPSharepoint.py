"""
Script: Update SharePoint Document Library Metadata from CSV
Description: Updates file metadata in SharePoint based on CSV data
"""

import pandas as pd
from office365.runtime.auth.user_credential import UserCredential
from office365.sharepoint.client_context import ClientContext
from office365.sharepoint.files.file import File
from datetime import datetime
import sys
from urllib.parse import quote

# ==========================================
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
# ==========================================

# Ø¢Ø¯Ø±Ø³ SharePoint Site
SITE_URL = "https://extranet.pedc.ir/pogp/PRD"

# Ù†Ø§Ù… Document Library
LIBRARY_NAME = "Production Engineering Report"

# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ CSV
CSV_FILE_PATH = "D:\Sepher_Pasargad\works\Maintenace\PythonDataAnalysis\PythonPractice\\Weekly.csv"

# Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆØ±ÙˆØ¯ (Ø¨Ø§ÛŒØ¯ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯)
USERNAME = "s.saeidi@pogp.ir"  # Ø§ÛŒÙ…ÛŒÙ„ ÛŒØ§ username Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
PASSWORD = "K@rensajad1367"          # Ù¾Ø³ÙˆØ±Ø¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯

# ==========================================
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# ==========================================

def connect_to_sharepoint(site_url, username, password):
    """Ø§ØªØµØ§Ù„ Ø¨Ù‡ SharePoint"""
    try:
        print("ğŸ”— Connecting to SharePoint...")
        credentials = UserCredential(username, password)
        ctx = ClientContext(site_url).with_credentials(credentials)
        
        # ØªØ³Øª Ø§ØªØµØ§Ù„
        web = ctx.web
        ctx.load(web)
        ctx.execute_query()
        
        print(f"âœ… Connected successfully to: {web.properties['Title']}")
        return ctx
    except Exception as e:
        print(f"âŒ Error connecting to SharePoint: {str(e)}")
        sys.exit(1)


def read_csv_file(csv_path):
    """Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV"""
    try:
        print(f"\nğŸ“‚ Reading CSV file: {csv_path}")
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† CSV Ø¨Ø§ encoding Ù…Ù†Ø§Ø³Ø¨
        df = pd.read_csv(csv_path, encoding='utf-8-sig')
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† whitespace Ø§Ø² Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        df.columns = df.columns.str.strip()
        
        print(f"âœ… Found {len(df)} rows in CSV")
        print(f"ğŸ“Š Columns: {', '.join(df.columns.tolist())}")
        
        return df
    except Exception as e:
        print(f"âŒ Error reading CSV file: {str(e)}")
        sys.exit(1)


def get_all_files(ctx, library_name):
    """Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Document Library"""
    try:
        print(f"\nğŸ“ Getting all files from '{library_name}'...")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª
        list_obj = ctx.web.lists.get_by_title(library_name)
        
        # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§
        items = list_obj.items.get_all(5000).execute_query()
        
        print(f"âœ… Found {len(items)} files in library")
        
        # Ø³Ø§Ø®Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±
        files_dict = {}
        for item in items:
            file_name = item.properties.get('FileLeafRef', '')
            if file_name:
                files_dict[file_name] = item
        
        return items, files_dict
    except Exception as e:
        print(f"âŒ Error getting files: {str(e)}")
        return [], {}


def update_file_metadata(ctx, item, row_data, library_name):
    """Ø¢Ù¾Ø¯ÛŒØª metadata ÛŒÚ© ÙØ§ÛŒÙ„"""
    try:
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª
        update_values = {}
        
        # ReportDate
        if pd.notna(row_data.get('ReportDate')):
            try:
                # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ ÙØ±Ù…Øª ISO
                date_str = str(row_data['ReportDate'])
                date_obj = pd.to_datetime(date_str)
                update_values['ReportDate'] = date_obj.strftime('%Y-%m-%dT%H:%M:%SZ')
            except:
                pass
        
        # Ø³Ø§ÛŒØ± ÙÛŒÙ„Ø¯Ù‡Ø§
        field_mappings = {
            'Pttern': 'Pttern',
            'Rev': 'Rev',
            'Process': 'Process',
            'Subprocess': 'Subprocess',
            'Location': 'Location',
            'Subject': 'Subject',
            'Type': 'Type',
            'Contractor': 'Contractor',
            'MainGroup': 'MainGroup'
        }
        
        for csv_field, sp_field in field_mappings.items():
            value = row_data.get(csv_field)
            if pd.notna(value) and str(value).strip():
                update_values[sp_field] = str(value).strip()
        
        # Ø¢Ù¾Ø¯ÛŒØª ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        if update_values:
            item.set_property_value_list(update_values)
            item.update()
            ctx.execute_query()
            return True, "Updated successfully"
        else:
            return False, "No values to update"
            
    except Exception as e:
        return False, f"Error: {str(e)}"


def find_matching_files(files_dict, report_no):
    """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Report No"""
    matching_files = []
    report_no_clean = str(report_no).strip()
    
    for file_name, item in files_dict.items():
        if report_no_clean in file_name:
            matching_files.append((file_name, item))
    
    return matching_files


# ==========================================
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
# ==========================================

def main():
    print("=" * 70)
    print("SharePoint Document Library Metadata Updater")
    print("=" * 70)
    
    # 1. Ø§ØªØµØ§Ù„ Ø¨Ù‡ SharePoint
    ctx = connect_to_sharepoint(SITE_URL, USERNAME, PASSWORD)
    
    # 2. Ø®ÙˆØ§Ù†Ø¯Ù† CSV
    df = read_csv_file(CSV_FILE_PATH)
    
    # 3. Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    all_items, files_dict = get_all_files(ctx, LIBRARY_NAME)
    
    if not files_dict:
        print("âŒ No files found in library!")
        return
    
    # 4. Ø¢Ù¾Ø¯ÛŒØª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    print("\n" + "=" * 70)
    print("Starting Update Process...")
    print("=" * 70)
    
    stats = {
        'total': len(df),
        'success': 0,
        'not_found': 0,
        'errors': 0,
        'no_update': 0
    }
    
    for index, row in df.iterrows():
        report_no = row.get('Report No', '')
        
        if pd.isna(report_no) or not str(report_no).strip():
            print(f"\nâš ï¸  Row {index + 1}: Missing Report No")
            stats['errors'] += 1
            continue
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        matching_files = find_matching_files(files_dict, report_no)
        
        if not matching_files:
            print(f"\nâš ï¸  Row {index + 1}: File not found for Report No: {report_no}")
            stats['not_found'] += 1
            continue
        
        # Ø¢Ù¾Ø¯ÛŒØª Ù‡Ø± ÙØ§ÛŒÙ„ Ù…Ø±ØªØ¨Ø·
        for file_name, item in matching_files:
            print(f"\nğŸ“ Row {index + 1}: Updating '{file_name}'")
            
            success, message = update_file_metadata(ctx, item, row, LIBRARY_NAME)
            
            if success:
                print(f"   âœ… {message}")
                stats['success'] += 1
            elif "No values" in message:
                print(f"   âŠ˜  {message}")
                stats['no_update'] += 1
            else:
                print(f"   âŒ {message}")
                stats['errors'] += 1
    
    # 5. Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡
    print("\n" + "=" * 70)
    print("Update Summary:")
    print("=" * 70)
    print(f"ğŸ“Š Total rows in CSV:      {stats['total']}")
    print(f"âœ… Successfully updated:   {stats['success']}")
    print(f"âŠ˜  No values to update:    {stats['no_update']}")
    print(f"âš ï¸  Files not found:        {stats['not_found']}")
    print(f"âŒ Errors:                 {stats['errors']}")
    print("=" * 70)
    
    print("\nâœ¨ Process completed!")


# ==========================================
# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
# ==========================================

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Process interrupted by user!")
        sys.exit(0)
    except Exception as e:
        print(f"\n\nâŒ Unexpected error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)